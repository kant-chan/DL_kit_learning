{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 100\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
    "                                           train=True,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
    "                                          train=False,\n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "print(len(train_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for images, labels in train_loader:\n",
    "#     pass\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "# print(images.size(), labels.size())\n",
    "\n",
    "img_num = 5\n",
    "counter = 0\n",
    "plt.figure()\n",
    "for i in range(img_num):\n",
    "    plt.subplot(1, img_num, i + 1)\n",
    "    plt.xlabel(labels[i].numpy())\n",
    "    img = torchvision.utils.make_grid(images[i]).numpy()\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc = nn.Linear(7 * 7 * 32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.1748\n",
      "Epoch [1/5], Step [200/600], Loss: 0.1271\n",
      "Epoch [1/5], Step [300/600], Loss: 0.1140\n",
      "Epoch [1/5], Step [400/600], Loss: 0.1380\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0643\n",
      "Epoch [1/5], Step [600/600], Loss: 0.0763\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0210\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0363\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0512\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0386\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0152\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0267\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0205\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0521\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0239\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0124\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0592\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0438\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0081\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0284\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0152\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0875\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0139\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0034\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0329\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0108\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0261\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0523\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0155\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0214\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet(num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "# print(total_step)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                 .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'troch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-baf7828cfebc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtroch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'troch' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print(\"Test Accuracy: {}%\".format(100 * correct / total))\n",
    "    \n",
    "# torch.save(model.state_dict(), './model/model.cpkt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
