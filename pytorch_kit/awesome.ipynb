{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "True False\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]]]) torch.float32\n",
      "torch.Size([1, 2, 3]) 1 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "a2 = torch.tensor([[1, 2], [3, 4]], requires_grad=True, dtype=torch.float32)\n",
    "a3 = a2.data\n",
    "print(type(a2.data), type(a2))\n",
    "print(a2.requires_grad, a2.data.requires_grad)\n",
    "\n",
    "a4 = a3.new(1, 2, 3).zero_()\n",
    "print(a4, a4.dtype)\n",
    "\n",
    "print(a4.size(), a4.size(0), type(a4.size(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]], grad_fn=<AddBackward0>) True\n",
      "tensor(3., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 3, requires_grad=True)\n",
    "y = x * x + 2\n",
    "out = y.mean()\n",
    "print(x.requires_grad)\n",
    "print(y, y.requires_grad)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**this is dynamic graph**\n",
    "\n",
    "when you run a second time bellow cell, will error:\n",
    "\n",
    "*Trying to backward through the graph a second time, but the buffers have already been freed*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# out.backward()\n",
    "out.backward(torch.tensor(3.))\n",
    "print(x.grad)\n",
    "print(y.grad)  # only x has grad ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor(3.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15., grad_fn=<AddBackward0>)\n",
      "tensor(3., requires_grad=True)\n",
      "tensor(14.)\n"
     ]
    }
   ],
   "source": [
    "# now this cell can run serval times, and x1.grad is accelerated\n",
    "# if y1 = x1 * x1 + x1 + 3 move up cell, this cell cannot run tow times.\n",
    "y1 = x1 * x1 + x1 + 3\n",
    "print(y1)\n",
    "y1.backward()\n",
    "print(x1)\n",
    "print(x1.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## about DOC api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Otherwise, contiguous() needs to be called before the tensor can be viewed. See also: reshape(), which returns a view if the shapes are compatible, and copies (equivalent to calling contiguous()) otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x3 = torch.ones(10, 10)\n",
    "print(x3.is_contiguous())  # True\n",
    "print(x3.transpose(0, 1).is_contiguous())  # False\n",
    "print(x3.transpose(0, 1).contiguous().is_contiguous())  # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5],\n",
      "         [6, 7, 8]]])\n",
      "tensor([[[1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1]]])\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n"
     ]
    }
   ],
   "source": [
    "x4 = torch.from_numpy(np.arange(0, 9))\n",
    "x4 = x4.view(1, 3, 3)\n",
    "x5 = torch.ones(2, 1, 3).type_as(x4)\n",
    "print(x4)\n",
    "print(x5)\n",
    "x6 = x4 + x5\n",
    "print(x6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### about slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  1.5 2.  2.5 3.  3.5 4.  4.5] (8,)\n",
      "1.0 ()\n",
      "[1.  1.5] (2,)\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "a1 = np.arange(1, 5, 0.5)\n",
    "print(a1, a1.shape)\n",
    "print(a1[0], a1[0].shape)\n",
    "print(a1[:2], a1[:2].shape)\n",
    "print(a1[0::9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### about shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4])\n",
    "torch.unsqueeze(x, 0)\n",
    "torch.unsqueeze(x, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### about sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4505, -1.0772, -0.0899, -1.0181],\n",
      "        [-0.5671, -0.0263, -0.5105, -0.4859],\n",
      "        [ 0.8140,  0.7063,  0.0172,  0.7241]])\n",
      "tensor([[ 1.4505, -0.0899, -1.0181, -1.0772],\n",
      "        [-0.0263, -0.4859, -0.5105, -0.5671],\n",
      "        [ 0.8140,  0.7241,  0.7063,  0.0172]])\n",
      "tensor([[0, 2, 3, 1],\n",
      "        [1, 3, 2, 0],\n",
      "        [0, 3, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "print(x)\n",
    "x_sorted, order = torch.sort(x, 1, True)\n",
    "print(x_sorted)\n",
    "print(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2046,  0.7479],\n",
      "        [-0.8057, -1.7067]])\n",
      "tensor([[0, 0],\n",
      "        [1, 1]], dtype=torch.uint8)\n",
      "tensor([[0.2046, 0.7479],\n",
      "        [1.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 2)\n",
    "print(x)\n",
    "print(x<0)\n",
    "x[x<0] = 1.\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
