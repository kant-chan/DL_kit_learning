{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method size of Tensor object at 0x7f6ca9095288>\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1.]),\n",
      "indices=tensor([2, 2]))\n",
      "tensor([0, 1, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(3)\n",
    "print(a.size)\n",
    "lg = a.size(0)\n",
    "torch.arange(lg).dtype\n",
    "\n",
    "a = torch.ones(3, 2, dtype=torch.float32)\n",
    "a1 = torch.max(a, 0)\n",
    "print(a1)\n",
    "\n",
    "t1 = torch.tensor([0, 1, 0, 1, 0, 0])\n",
    "t2 = torch.tensor([0, 1, 1, 0, 1, 0])\n",
    "t3 = t1 & t2\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "True False\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]]]) torch.float32\n",
      "torch.Size([1, 2, 3]) 1 <class 'int'>\n",
      "tensor([0., 0., 0., 0.]) torch.float32\n",
      "tensor([[ 2.0655,  1.0536],\n",
      "        [-2.0452,  0.7222],\n",
      "        [-1.6556,  0.0340]]) torch.float32 False\n",
      "tensor([ 2,  1, -2,  0, -1,  0]) torch.int64 False\n",
      "tensor([ 2,  1, -2,  0, -1,  0]) torch.int64 False\n",
      "************\n",
      "tensor([[-1.6682,  0.7630,  0.0081],\n",
      "        [-0.5083,  0.2246, -0.3151]])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "a2 = torch.tensor([[1, 2], [3, 4]], requires_grad=True, dtype=torch.float32)\n",
    "a3 = a2.data\n",
    "print(type(a2.data), type(a2))\n",
    "print(a2.requires_grad, a2.data.requires_grad)\n",
    "\n",
    "a4 = a3.new(1, 2, 3).zero_()\n",
    "print(a4, a4.dtype)\n",
    "\n",
    "print(a4.size(), a4.size(0), type(a4.size(0)))\n",
    "\n",
    "a5 = torch.FloatTensor([0., 0., 0., 0.])\n",
    "print(a5, a5.dtype)\n",
    "\n",
    "\n",
    "# pytorch version tansfer\n",
    "from torch.autograd import Variable\n",
    "b1 = torch.randn(3, 2)\n",
    "print(b1, b1.dtype, b1.requires_grad)\n",
    "b2 = b1.view(-1).long()\n",
    "print(b2, b2.dtype, b2.requires_grad)\n",
    "b3 = Variable(b2)\n",
    "print(b3, b3.dtype, b3.requires_grad)\n",
    "\n",
    "print('************')\n",
    "c1 = torch.randn(2, 3, dtype=torch.float32, requires_grad=False)\n",
    "c2 = c1.unsqueeze(0)\n",
    "print(c1)\n",
    "print(c2 is c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]], grad_fn=<AddBackward0>) True\n",
      "tensor(3., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 3, requires_grad=True)\n",
    "y = x * x + 2\n",
    "out = y.mean()\n",
    "print(x.requires_grad)\n",
    "print(y, y.requires_grad)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**this is dynamic graph**\n",
    "\n",
    "when you run a second time bellow cell, will error:\n",
    "\n",
    "*Trying to backward through the graph a second time, but the buffers have already been freed*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# out.backward()\n",
    "out.backward(torch.tensor(3.))\n",
    "print(x.grad)\n",
    "print(y.grad)  # only x has grad ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor(3.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15., grad_fn=<AddBackward0>)\n",
      "tensor(3., requires_grad=True)\n",
      "tensor(14.)\n"
     ]
    }
   ],
   "source": [
    "# now this cell can run serval times, and x1.grad is accelerated\n",
    "# if y1 = x1 * x1 + x1 + 3 move up cell, this cell cannot run tow times.\n",
    "y1 = x1 * x1 + x1 + 3\n",
    "print(y1)\n",
    "y1.backward()\n",
    "print(x1)\n",
    "print(x1.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## about DOC api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Otherwise, contiguous() needs to be called before the tensor can be viewed. See also: reshape(), which returns a view if the shapes are compatible, and copies (equivalent to calling contiguous()) otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x3 = torch.ones(10, 10)\n",
    "print(x3.is_contiguous())  # True\n",
    "print(x3.transpose(0, 1).is_contiguous())  # False\n",
    "print(x3.transpose(0, 1).contiguous().is_contiguous())  # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5],\n",
      "         [6, 7, 8]]])\n",
      "tensor([[[1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1]]])\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n"
     ]
    }
   ],
   "source": [
    "x4 = torch.from_numpy(np.arange(0, 9))\n",
    "x4 = x4.view(1, 3, 3)\n",
    "x5 = torch.ones(2, 1, 3).type_as(x4)\n",
    "print(x4)\n",
    "print(x5)\n",
    "x6 = x4 + x5\n",
    "print(x6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### about slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  1.5 2.  2.5 3.  3.5 4.  4.5] (8,)\n",
      "1.0 ()\n",
      "[1.  1.5] (2,)\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "a1 = np.arange(1, 5, 0.5)\n",
    "print(a1, a1.shape)\n",
    "print(a1[0], a1[0].shape)\n",
    "print(a1[:2], a1[:2].shape)\n",
    "print(a1[0::9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### about shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4])\n",
    "torch.unsqueeze(x, 0)\n",
    "torch.unsqueeze(x, 1)\n",
    "\n",
    "x1 = torch.randn(1, 2, 3, 4)\n",
    "x2 = x1.view(1, 2, -1, 2)\n",
    "print(x2.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### about sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4505, -1.0772, -0.0899, -1.0181],\n",
      "        [-0.5671, -0.0263, -0.5105, -0.4859],\n",
      "        [ 0.8140,  0.7063,  0.0172,  0.7241]])\n",
      "tensor([[ 1.4505, -0.0899, -1.0181, -1.0772],\n",
      "        [-0.0263, -0.4859, -0.5105, -0.5671],\n",
      "        [ 0.8140,  0.7241,  0.7063,  0.0172]])\n",
      "tensor([[0, 2, 3, 1],\n",
      "        [1, 3, 2, 0],\n",
      "        [0, 3, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "print(x)\n",
    "x_sorted, order = torch.sort(x, 1, True)\n",
    "print(x_sorted)\n",
    "print(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2046,  0.7479],\n",
      "        [-0.8057, -1.7067]])\n",
      "tensor([[0, 0],\n",
      "        [1, 1]], dtype=torch.uint8)\n",
      "tensor([[0.2046, 0.7479],\n",
      "        [1.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 2)\n",
    "print(x)\n",
    "print(x<0)\n",
    "x[x<0] = 1.\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
